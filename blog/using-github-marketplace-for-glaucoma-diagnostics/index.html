<!doctype html>
<html lang="en" dir="ltr" class="blog-wrapper blog-post-page plugin-blog plugin-id-default" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.6.0">
<title data-rh="true">Exploring Medical Diagnostic LLMs: A Comprehensive Guide to Using GitHub&#x27;s Model Marketplace for Glaucoma Detection in Retinographies | LLMs and Fine Tuning in glaucoma detection</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://edujbarrios.github.io/My-TFG-Logbook/img/social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://edujbarrios.github.io/My-TFG-Logbook/img/social-card.jpg"><meta data-rh="true" property="og:url" content="https://edujbarrios.github.io/My-TFG-Logbook/blog/using-github-marketplace-for-glaucoma-diagnostics"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" property="og:locale:alternate" content="es"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docusaurus_tag" content="default"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docsearch:docusaurus_tag" content="default"><meta data-rh="true" property="og:title" content="Exploring Medical Diagnostic LLMs: A Comprehensive Guide to Using GitHub&#x27;s Model Marketplace for Glaucoma Detection in Retinographies | LLMs and Fine Tuning in glaucoma detection"><meta data-rh="true" name="description" content="Artificial intelligence (AI) is rapidly evolving in the field of medical diagnostics, particularly with the support of large language models (LLMs) trained to interpret medical images. By utilizing models available on the GitHub Model Marketplace, professionals and developers can test various LLMs on specific tasks, such as analyzing retinographies to detect signs of glaucoma. This guide walks you through setting up a medical diagnostic model from GitHub’s Marketplace to evaluate its performance on glaucoma detection."><meta data-rh="true" property="og:description" content="Artificial intelligence (AI) is rapidly evolving in the field of medical diagnostics, particularly with the support of large language models (LLMs) trained to interpret medical images. By utilizing models available on the GitHub Model Marketplace, professionals and developers can test various LLMs on specific tasks, such as analyzing retinographies to detect signs of glaucoma. This guide walks you through setting up a medical diagnostic model from GitHub’s Marketplace to evaluate its performance on glaucoma detection."><meta data-rh="true" property="og:type" content="article"><meta data-rh="true" property="article:published_time" content="2024-11-10T20:39:32.000Z"><meta data-rh="true" property="article:author" content="https://github.com/edujbarrios"><meta data-rh="true" property="article:tag" content="LLMs,GitHub Marketplace,medical imaging,retinography,glaucoma detection,AI,fine-tuning"><link data-rh="true" rel="icon" href="/My-TFG-Logbook/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://edujbarrios.github.io/My-TFG-Logbook/blog/using-github-marketplace-for-glaucoma-diagnostics"><link data-rh="true" rel="alternate" href="https://edujbarrios.github.io/My-TFG-Logbook/blog/using-github-marketplace-for-glaucoma-diagnostics" hreflang="en"><link data-rh="true" rel="alternate" href="https://edujbarrios.github.io/My-TFG-Logbook/es/blog/using-github-marketplace-for-glaucoma-diagnostics" hreflang="es"><link data-rh="true" rel="alternate" href="https://edujbarrios.github.io/My-TFG-Logbook/blog/using-github-marketplace-for-glaucoma-diagnostics" hreflang="x-default"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","@id":"https://edujbarrios.github.io/My-TFG-Logbook/blog/using-github-marketplace-for-glaucoma-diagnostics","mainEntityOfPage":"https://edujbarrios.github.io/My-TFG-Logbook/blog/using-github-marketplace-for-glaucoma-diagnostics","url":"https://edujbarrios.github.io/My-TFG-Logbook/blog/using-github-marketplace-for-glaucoma-diagnostics","headline":"Exploring Medical Diagnostic LLMs: A Comprehensive Guide to Using GitHub's Model Marketplace for Glaucoma Detection in Retinographies","name":"Exploring Medical Diagnostic LLMs: A Comprehensive Guide to Using GitHub's Model Marketplace for Glaucoma Detection in Retinographies","description":"Artificial intelligence (AI) is rapidly evolving in the field of medical diagnostics, particularly with the support of large language models (LLMs) trained to interpret medical images. By utilizing models available on the GitHub Model Marketplace, professionals and developers can test various LLMs on specific tasks, such as analyzing retinographies to detect signs of glaucoma. This guide walks you through setting up a medical diagnostic model from GitHub’s Marketplace to evaluate its performance on glaucoma detection.","datePublished":"2024-11-10T20:39:32.000Z","author":{"@type":"Person","name":"Eduardo José Barrios García","description":"LLM and Neural Networks researcher at Universidad de La Laguna","url":"https://github.com/edujbarrios","image":"https://github.com/edujbarrios.png"},"keywords":[],"isPartOf":{"@type":"Blog","@id":"https://edujbarrios.github.io/My-TFG-Logbook/blog","name":"Blog"}}</script><link rel="alternate" type="application/rss+xml" href="/My-TFG-Logbook/blog/rss.xml" title="LLMs and Fine Tuning in glaucoma detection RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/My-TFG-Logbook/blog/atom.xml" title="LLMs and Fine Tuning in glaucoma detection Atom Feed"><link rel="stylesheet" href="/My-TFG-Logbook/assets/css/styles.9760b7e3.css">
<script src="/My-TFG-Logbook/assets/js/runtime~main.5df3592d.js" defer="defer"></script>
<script src="/My-TFG-Logbook/assets/js/main.4d676938.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();t(null!==e?e:"dark")}(),function(){try{const n=new URLSearchParams(window.location.search).entries();for(var[t,e]of n)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/My-TFG-Logbook/"><div class="navbar__logo"><img src="/My-TFG-Logbook/img/logo.png" alt="My Site Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/My-TFG-Logbook/img/logo.png" alt="My Site Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">LLMs and fine tuning in glaucoma detection </b></a><a class="navbar__item navbar__link" href="/My-TFG-Logbook/docs/">Docs</a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/My-TFG-Logbook/blog">Blog</a></div><div class="navbar__items navbar__items--right"><a href="https://github.com/edujbarrios" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently dark mode)" aria-label="Switch between dark and light mode (currently dark mode)" aria-live="polite" aria-pressed="true"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="container margin-vert--lg"><div class="row"><aside class="col col--3"><nav class="sidebar_re4s thin-scrollbar" aria-label="Blog recent posts navigation"><div class="sidebarItemTitle_pO2u margin-bottom--md">Recent posts</div><div role="group"><h3 class="yearGroupHeading_rMGB">2024</h3><ul class="sidebarItemList_Yudw clean-list"><li class="sidebarItem__DBe"><a aria-current="page" class="sidebarItemLink_mo7H sidebarItemLinkActive_I1ZP" href="/My-TFG-Logbook/blog/using-github-marketplace-for-glaucoma-diagnostics">Exploring Medical Diagnostic LLMs: A Comprehensive Guide to Using GitHub&#x27;s Model Marketplace for Glaucoma Detection in Retinographies</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/My-TFG-Logbook/blog/neural-networks-fine-tuning-llms">Leveraging Neural Networks and Fine-Tuning in Large Language Models: A Synergy for Enhanced AI Capabilities</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/My-TFG-Logbook/blog/prompt-engineering-medical-diagnostics">Enhancing Medical Diagnostics with Prompt Engineering: A Deep Dive into AI Accuracy and Potential</a></li></ul></div></nav></aside><main class="col col--7"><article><header><h1 class="title_f1Hy">Exploring Medical Diagnostic LLMs: A Comprehensive Guide to Using GitHub&#x27;s Model Marketplace for Glaucoma Detection in Retinographies</h1><div class="container_mt6G margin-vert--md"><time datetime="2024-11-10T20:39:32.000Z">November 10, 2024</time> · <!-- -->6 min read</div><div class="margin-top--md margin-bottom--sm row"><div class="col col--12 authorCol_Hf19"><div class="avatar margin-bottom--sm"><a class="avatar__photo-link" href="/My-TFG-Logbook/blog/authors/all-sebastien-lorber-articles"><img class="avatar__photo authorImage_XqGP" src="https://github.com/edujbarrios.png" alt="Eduardo José Barrios García"></a><div class="avatar__intro authorDetails_lV9A"><div class="avatar__name"><a href="/My-TFG-Logbook/blog/authors/all-sebastien-lorber-articles"><span class="authorName_yefp">Eduardo José Barrios García</span></a></div><small class="authorTitle_nd0D" title="LLM and Neural Networks researcher at Universidad de La Laguna">LLM and Neural Networks researcher at Universidad de La Laguna</small><div class="authorSocials_rSDt"><a href="https://x.com/eyemadmusic" target="_blank" rel="noopener noreferrer" class="authorSocialLink_owbf" title="X"><svg xmlns="http://www.w3.org/2000/svg" width="1em" height="1em" fill="none" viewBox="0 0 1200 1227" class="authorSocialLink_owbf xSvg_y3PF" style="--dark:#000;--light:#fff"><path d="M714.163 519.284 1160.89 0h-105.86L667.137 450.887 357.328 0H0l468.492 681.821L0 1226.37h105.866l409.625-476.152 327.181 476.152H1200L714.137 519.284h.026ZM569.165 687.828l-47.468-67.894-377.686-540.24h162.604l304.797 435.991 47.468 67.894 396.2 566.721H892.476L569.165 687.854v-.026Z"></path></svg></a><a href="https://github.com/edujbarrios" target="_blank" rel="noopener noreferrer" class="authorSocialLink_owbf" title="GitHub"><svg viewBox="0 0 256 250" width="1em" height="1em" class="authorSocialLink_owbf githubSvg_Uu4N" xmlns="http://www.w3.org/2000/svg" style="--dark:#000;--light:#fff" preserveAspectRatio="xMidYMid"><path d="M128.001 0C57.317 0 0 57.307 0 128.001c0 56.554 36.676 104.535 87.535 121.46 6.397 1.185 8.746-2.777 8.746-6.158 0-3.052-.12-13.135-.174-23.83-35.61 7.742-43.124-15.103-43.124-15.103-5.823-14.795-14.213-18.73-14.213-18.73-11.613-7.944.876-7.78.876-7.78 12.853.902 19.621 13.19 19.621 13.19 11.417 19.568 29.945 13.911 37.249 10.64 1.149-8.272 4.466-13.92 8.127-17.116-28.431-3.236-58.318-14.212-58.318-63.258 0-13.975 5-25.394 13.188-34.358-1.329-3.224-5.71-16.242 1.24-33.874 0 0 10.749-3.44 35.21 13.121 10.21-2.836 21.16-4.258 32.038-4.307 10.878.049 21.837 1.47 32.066 4.307 24.431-16.56 35.165-13.12 35.165-13.12 6.967 17.63 2.584 30.65 1.255 33.873 8.207 8.964 13.173 20.383 13.173 34.358 0 49.163-29.944 59.988-58.447 63.157 4.591 3.972 8.682 11.762 8.682 23.704 0 17.126-.148 30.91-.148 35.126 0 3.407 2.304 7.398 8.792 6.14C219.37 232.5 256 184.537 256 128.002 256 57.307 198.691 0 128.001 0Zm-80.06 182.34c-.282.636-1.283.827-2.194.39-.929-.417-1.45-1.284-1.15-1.922.276-.655 1.279-.838 2.205-.399.93.418 1.46 1.293 1.139 1.931Zm6.296 5.618c-.61.566-1.804.303-2.614-.591-.837-.892-.994-2.086-.375-2.66.63-.566 1.787-.301 2.626.591.838.903 1 2.088.363 2.66Zm4.32 7.188c-.785.545-2.067.034-2.86-1.104-.784-1.138-.784-2.503.017-3.05.795-.547 2.058-.055 2.861 1.075.782 1.157.782 2.522-.019 3.08Zm7.304 8.325c-.701.774-2.196.566-3.29-.49-1.119-1.032-1.43-2.496-.726-3.27.71-.776 2.213-.558 3.315.49 1.11 1.03 1.45 2.505.701 3.27Zm9.442 2.81c-.31 1.003-1.75 1.459-3.199 1.033-1.448-.439-2.395-1.613-2.103-2.626.301-1.01 1.747-1.484 3.207-1.028 1.446.436 2.396 1.602 2.095 2.622Zm10.744 1.193c.036 1.055-1.193 1.93-2.715 1.95-1.53.034-2.769-.82-2.786-1.86 0-1.065 1.202-1.932 2.733-1.958 1.522-.03 2.768.818 2.768 1.868Zm10.555-.405c.182 1.03-.875 2.088-2.387 2.37-1.485.271-2.861-.365-3.05-1.386-.184-1.056.893-2.114 2.376-2.387 1.514-.263 2.868.356 3.061 1.403Z"></path></svg></a></div></div></div></div></div></header><div id="__blog-post-container" class="markdown"><p>Artificial intelligence (AI) is rapidly evolving in the field of medical diagnostics, particularly with the support of <strong>large language models (LLMs)</strong> trained to interpret medical images. By utilizing models available on the <strong>GitHub Model Marketplace</strong>, professionals and developers can test various LLMs on specific tasks, such as analyzing retinographies to detect signs of glaucoma. This guide walks you through setting up a medical diagnostic model from GitHub’s Marketplace to evaluate its performance on glaucoma detection.</p>
<p>Additionally, we discuss how these steps can lay the groundwork for potential <strong>fine-tuning</strong>, allowing models to be further optimized for even higher accuracy in specific diagnostic contexts.</p>
<!-- -->
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="introduction">Introduction<a href="#introduction" class="hash-link" aria-label="Direct link to Introduction" title="Direct link to Introduction">​</a></h2>
<p>As healthcare progresses, the role of AI in diagnostics—especially in <strong>medical imaging</strong>—is becoming indispensable. With access to models that can analyze retinographies, healthcare providers have new tools that complement their expertise, enhancing accuracy and response times.</p>
<p>GitHub&#x27;s Model Marketplace offers a broad selection of pre-trained LLMs, including models fine-tuned for medical diagnostics. These models can be evaluated on specific tasks to understand their effectiveness in real-world medical applications and explore where future <strong>fine-tuning</strong> could provide further enhancements.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="step-by-step-guide-to-using-github-model-marketplace">Step-by-Step Guide to Using GitHub Model Marketplace<a href="#step-by-step-guide-to-using-github-model-marketplace" class="hash-link" aria-label="Direct link to Step-by-Step Guide to Using GitHub Model Marketplace" title="Direct link to Step-by-Step Guide to Using GitHub Model Marketplace">​</a></h2>
<p>The GitHub Model Marketplace provides access to a variety of models tailored for different diagnostic tasks. In this guide, we’ll demonstrate how to use these models to analyze a retinography and assess their diagnostic capabilities for glaucoma detection.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="step-1-finding-a-model-in-the-marketplace">Step 1: Finding a Model in the Marketplace<a href="#step-1-finding-a-model-in-the-marketplace" class="hash-link" aria-label="Direct link to Step 1: Finding a Model in the Marketplace" title="Direct link to Step 1: Finding a Model in the Marketplace">​</a></h3>
<ol>
<li>Go to the <strong>GitHub Model Marketplace</strong> and search for relevant medical diagnostic models, such as those trained on retinography analysis.</li>
<li>Select a model that suits your diagnostic needs. Review model descriptions to ensure it has been fine-tuned on medical imaging data specific to retinal images, which is essential for reliable results.</li>
</ol>
<p>This first step allows you to choose a model that is already partially prepared for diagnostic tasks in ophthalmology, although these models may benefit from additional fine-tuning in the future for even more accurate results.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="step-2-setting-up-your-environment">Step 2: Setting Up Your Environment<a href="#step-2-setting-up-your-environment" class="hash-link" aria-label="Direct link to Step 2: Setting Up Your Environment" title="Direct link to Step 2: Setting Up Your Environment">​</a></h3>
<p>To get started, make sure you have the necessary libraries installed, such as <code>torch</code>, <code>transformers</code>, and <code>PIL</code> for image processing. You can install them using:</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">pip install torch transformers pillow</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>Setting up a consistent environment ensures reproducibility and allows for seamless testing across multiple models.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="step-3-loading-and-testing-the-model">Step 3: Loading and Testing the Model<a href="#step-3-loading-and-testing-the-model" class="hash-link" aria-label="Direct link to Step 3: Loading and Testing the Model" title="Direct link to Step 3: Loading and Testing the Model">​</a></h3>
<p>The next step is to load the chosen model from the GitHub Model Marketplace and apply it to a retinography image:</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">from</span><span class="token plain"> transformers </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">import</span><span class="token plain"> AutoModelForImageClassification</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> AutoFeatureExtractor</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">from</span><span class="token plain"> PIL </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">import</span><span class="token plain"> Image</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">import</span><span class="token plain"> torch</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token comment" style="color:rgb(98, 114, 164)"># Load model from GitHub Model Marketplace</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">model_name </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">&quot;your-chosen-model&quot;</span><span class="token plain">  </span><span class="token comment" style="color:rgb(98, 114, 164)"># Replace with the model ID from the marketplace</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">model </span><span class="token operator">=</span><span class="token plain"> AutoModelForImageClassification</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">from_pretrained</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">model_name</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">feature_extractor </span><span class="token operator">=</span><span class="token plain"> AutoFeatureExtractor</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">from_pretrained</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">model_name</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token comment" style="color:rgb(98, 114, 164)"># Load a retinography image</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">image </span><span class="token operator">=</span><span class="token plain"> Image</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token builtin" style="color:rgb(189, 147, 249)">open</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token string" style="color:rgb(255, 121, 198)">&quot;path_to_retinography_image.jpg&quot;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">inputs </span><span class="token operator">=</span><span class="token plain"> feature_extractor</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">images</span><span class="token operator">=</span><span class="token plain">image</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> return_tensors</span><span class="token operator">=</span><span class="token string" style="color:rgb(255, 121, 198)">&quot;pt&quot;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token comment" style="color:rgb(98, 114, 164)"># Make predictions</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">with</span><span class="token plain"> torch</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">no_grad</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    outputs </span><span class="token operator">=</span><span class="token plain"> model</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token operator">**</span><span class="token plain">inputs</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    predictions </span><span class="token operator">=</span><span class="token plain"> torch</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">nn</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">functional</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">softmax</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">outputs</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">logits</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> dim</span><span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">print</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token string" style="color:rgb(255, 121, 198)">&quot;Prediction results:&quot;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> predictions</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>This step allows you to assess the model&#x27;s baseline performance, which could be refined with future fine-tuning tailored to glaucoma detection.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="step-4-setting-a-role-specific-prompt">Step 4: Setting a Role-Specific Prompt<a href="#step-4-setting-a-role-specific-prompt" class="hash-link" aria-label="Direct link to Step 4: Setting a Role-Specific Prompt" title="Direct link to Step 4: Setting a Role-Specific Prompt">​</a></h3>
<p>For a more accurate assessment, defining a specific role that aligns with the diagnostic goal can direct the model’s focus. In this case, we’ll assume the role of an <strong>ophthalmologist focusing on glaucoma detection</strong>:</p>
<ul>
<li>Adjust the input prompt or model configuration to specify: <strong>&quot;As an ophthalmologist specializing in glaucoma detection, analyze this retinography for signs of glaucoma. Pay special attention to optic nerve cupping, retinal nerve fiber layer thinning, and characteristic glaucomatous changes that could indicate early-stage or advanced glaucoma.&quot;</strong></li>
</ul>
<p>This prompt introduces role-specific expertise, helping the model prioritize clinically relevant features for glaucoma, such as optic nerve health and retinal changes.</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token comment" style="color:rgb(98, 114, 164)"># Example prompt setting (if supported by the model or input setup)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">prompt </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">&quot;As an ophthalmologist specializing in glaucoma detection, assess this retinography for optic nerve cupping, retinal thinning, and glaucomatous changes.&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token comment" style="color:rgb(98, 114, 164)"># Adjust model inputs or preprocessing as required by the model&#x27;s API.</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>This step not only adds clarity to the model’s task but also opens up the possibility of fine-tuning. By collecting results from multiple cases, you can refine prompts and data inputs for better outcomes, especially for highly specific diagnostic tasks.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="step-5-evaluating-model-performance">Step 5: Evaluating Model Performance<a href="#step-5-evaluating-model-performance" class="hash-link" aria-label="Direct link to Step 5: Evaluating Model Performance" title="Direct link to Step 5: Evaluating Model Performance">​</a></h3>
<p>Once you have the model configured, evaluate its performance with metrics like <strong>accuracy</strong>, <strong>sensitivity</strong>, and <strong>specificity</strong> to determine its effectiveness in detecting glaucoma.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="potential-for-fine-tuning">Potential for Fine-Tuning<a href="#potential-for-fine-tuning" class="hash-link" aria-label="Direct link to Potential for Fine-Tuning" title="Direct link to Potential for Fine-Tuning">​</a></h3>
<p>With diagnostic tasks as specialized as glaucoma detection, there is significant potential for <strong>fine-tuning</strong>. Fine-tuning involves training the model on a dataset specifically curated for glaucoma or other ophthalmologic conditions, allowing it to learn patterns and markers associated with these diseases in detail.</p>
<p>By fine-tuning on a large dataset of labeled retinographies, for instance, the model can learn nuanced patterns that may indicate early-stage glaucoma. Fine-tuning could be conducted with frameworks such as <strong>PyTorch</strong> or <strong>TensorFlow</strong>, and would require a labeled dataset of glaucoma-positive and negative cases for best results.</p>
<p>Fine-tuning steps could involve:</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">from</span><span class="token plain"> transformers </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">import</span><span class="token plain"> Trainer</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> TrainingArguments</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token comment" style="color:rgb(98, 114, 164)"># Training parameters</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">training_args </span><span class="token operator">=</span><span class="token plain"> TrainingArguments</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    output_dir</span><span class="token operator">=</span><span class="token string" style="color:rgb(255, 121, 198)">&quot;./results&quot;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    num_train_epochs</span><span class="token operator">=</span><span class="token number">3</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    per_device_train_batch_size</span><span class="token operator">=</span><span class="token number">8</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    logging_dir</span><span class="token operator">=</span><span class="token string" style="color:rgb(255, 121, 198)">&quot;./logs&quot;</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token comment" style="color:rgb(98, 114, 164)"># Set up Trainer with the labeled retinography dataset</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">trainer </span><span class="token operator">=</span><span class="token plain"> Trainer</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    model</span><span class="token operator">=</span><span class="token plain">model</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    args</span><span class="token operator">=</span><span class="token plain">training_args</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    train_dataset</span><span class="token operator">=</span><span class="token plain">glaucoma_dataset</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain">  </span><span class="token comment" style="color:rgb(98, 114, 164)"># replace with your glaucoma-specific dataset</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">trainer</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">train</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>This added step not only enhances diagnostic accuracy but also customizes the model for specific needs in glaucoma detection, potentially aiding in the early diagnosis of this sight-threatening condition.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="best-practices">Best Practices<a href="#best-practices" class="hash-link" aria-label="Direct link to Best Practices" title="Direct link to Best Practices">​</a></h3>
<ul>
<li><strong>Data Preparation</strong>: Ensure the input images are high quality and properly preprocessed for optimal accuracy.</li>
<li><strong>Prompt Customization</strong>: Tailor prompts to emphasize specific indicators of glaucoma in retinography images.</li>
<li><strong>Performance Metrics</strong>: Use relevant metrics like <strong>accuracy</strong>, <strong>sensitivity</strong>, and <strong>specificity</strong> to assess model reliability in detecting glaucoma.</li>
<li><strong>Iterative Fine-Tuning</strong>: As more labeled data becomes available, consider additional rounds of fine-tuning for increased diagnostic precision.</li>
</ul>
<div class="theme-admonition theme-admonition-tip admonition_xJq3 alert alert--success"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 12 16"><path fill-rule="evenodd" d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"></path></svg></span>tip</div><div class="admonitionContent_BuS1"><p>Utilizing GitHub&#x27;s Model Marketplace lets you experiment with a variety of models, helping you find the most effective options for specific diagnostic tasks, such as glaucoma detection.</p></div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="conclusion">Conclusion<a href="#conclusion" class="hash-link" aria-label="Direct link to Conclusion" title="Direct link to Conclusion">​</a></h2>
<p>Testing LLMs from the GitHub Model Marketplace allows healthcare providers and AI developers to explore state-of-the-art models in medical diagnostics. With easy access to these tools, professionals can enhance diagnostic precision, adding valuable support to traditional medical practices. Fine-tuning opportunities also mean these models can be continually improved, offering the potential for ongoing advancements in glaucoma detection and beyond.</p>
<hr></div><footer class="docusaurus-mt-lg"><div class="row margin-top--sm theme-blog-footer-edit-meta-row"><div class="col"><b>Tags:</b><ul class="tags_jXut padding--none margin-left--sm"><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/My-TFG-Logbook/blog/tags/ll-ms">LLMs</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/My-TFG-Logbook/blog/tags/git-hub-marketplace">GitHub Marketplace</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/My-TFG-Logbook/blog/tags/medical-imaging">medical imaging</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/My-TFG-Logbook/blog/tags/retinography">retinography</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/My-TFG-Logbook/blog/tags/glaucoma-detection">glaucoma detection</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/My-TFG-Logbook/blog/tags/ai">AI</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/My-TFG-Logbook/blog/tags/fine-tuning">fine-tuning</a></li></ul></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Blog post page navigation"><a class="pagination-nav__link pagination-nav__link--next" href="/My-TFG-Logbook/blog/neural-networks-fine-tuning-llms"><div class="pagination-nav__sublabel">Older post</div><div class="pagination-nav__label">Leveraging Neural Networks and Fine-Tuning in Large Language Models: A Synergy for Enhanced AI Capabilities</div></a></nav></main><div class="col col--2"><div class="tableOfContents_bqdL thin-scrollbar"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#introduction" class="table-of-contents__link toc-highlight">Introduction</a></li><li><a href="#step-by-step-guide-to-using-github-model-marketplace" class="table-of-contents__link toc-highlight">Step-by-Step Guide to Using GitHub Model Marketplace</a><ul><li><a href="#step-1-finding-a-model-in-the-marketplace" class="table-of-contents__link toc-highlight">Step 1: Finding a Model in the Marketplace</a></li><li><a href="#step-2-setting-up-your-environment" class="table-of-contents__link toc-highlight">Step 2: Setting Up Your Environment</a></li><li><a href="#step-3-loading-and-testing-the-model" class="table-of-contents__link toc-highlight">Step 3: Loading and Testing the Model</a></li><li><a href="#step-4-setting-a-role-specific-prompt" class="table-of-contents__link toc-highlight">Step 4: Setting a Role-Specific Prompt</a></li><li><a href="#step-5-evaluating-model-performance" class="table-of-contents__link toc-highlight">Step 5: Evaluating Model Performance</a></li><li><a href="#potential-for-fine-tuning" class="table-of-contents__link toc-highlight">Potential for Fine-Tuning</a></li><li><a href="#best-practices" class="table-of-contents__link toc-highlight">Best Practices</a></li></ul></li><li><a href="#conclusion" class="table-of-contents__link toc-highlight">Conclusion</a></li></ul></div></div></div></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Docs</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/My-TFG-Logbook/docs">Introduction to Docs</a></li></ul></div><div class="col footer__col"><div class="footer__title">Social Links</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://x.com/test" target="_blank" rel="noopener noreferrer" class="footer__link-item">X - Not working by now<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="col footer__col"><div class="footer__title">Important Links</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/My-TFG-Logbook/blog">Blog</a></li><li class="footer__item"><a href="https://github.com/edujbarrios" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2024 Eduardo José Barrios García.</div></div></div></footer></div>
</body>
</html>