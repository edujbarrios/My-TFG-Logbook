---
sidebar_position: 3
---

# Bonus: State of the Art

I discovered this resource, which has a highly complex (and computationally costly) operation in terms of usage for a final degree project. However, it successfully performs fine-tuning with multiple LLMs in an automated way:

- [Video Explanation](https://youtu.be/W29FgeZEpus?feature=shared)

Additionally, this guide specifies how to set it up for a specific dataset:

- [Dataset Setup Guide](https://github.com/hiyouga/LLaMA-Factory/blob/main/data/README.md)

Using this resource in the project would be challenging, as mentioned, but it provides a valuable reference for the state of the art. The project is still in active development, with the latest commits only 1-2 days ago. For more advanced research, it could be extremely useful.

- [LLaMA-Factory GitHub Repository](https://github.com/hiyouga/LLaMA-Factory)

They also have a paper explaining what LLaMA-Factory is:

- [LLaMA-Factory Research Paper (arXiv)](https://arxiv.org/abs/2403.13372)

It appears that combining fine-tuning with LLMs is an emerging research area. I'll stop exploring new resources for now and focus on the previous LLM tool I found on the last page, and testing its code and capabilites, but LLaMA-Factory could be an excellent reference for the state of the art.
