---
sidebar_position: 3
---

# State of the Art

I discovered this resource, which has a highly complex (and computationally costly) operation in terms of usage for a final degree project. However, it successfully performs fine-tuning with multiple LLMs in an automated way:

- [Video Explanation](https://youtu.be/W29FgeZEpus?feature=shared)

Additionally, this guide specifies how to set it up for a specific dataset:

- [Dataset Setup Guide](https://github.com/hiyouga/LLaMA-Factory/blob/main/data/README.md)

Using this resource in the project would be challenging, as mentioned, but it provides a valuable reference for the state of the art. The project is still in active development, with the latest commits only 1-2 days ago, as consulted in 19th november. For more advanced research, it could be extremely useful.

- [LLaMA-Factory GitHub Repository](https://github.com/hiyouga/LLaMA-Factory)

They also have a paper explaining what LLaMA-Factory is:

- [LLaMA-Factory Research Paper (arXiv)](https://arxiv.org/abs/2403.13372)


In addition, I came across another repository called **MI-Zero** ([GitHub Repository](https://github.com/mahmoodlab/MI-Zero)), which explores the application of **zero-shot learning** to medical images. This approach is particularly interesting for diagnostic applications in medical imaging. You can also check out their paper for detailed insights:

- [MI-Zero Research Paper (arXiv)](https://arxiv.org/abs/2306.07831)

Both approaches have inspired me to develop a prototype in Spanish, demonstrating how to perform **zero-shot learning** linked with CLIP. The prototype is available here:

- [Prototype Notebook](https://github.com/edujbarrios/My-TFG-Logbook/blob/main/notebooks/Probando_ZeroShot_como_altenativa_a_Llama.ipynb)

**New updates on the State Of The Art, will be added here.**
