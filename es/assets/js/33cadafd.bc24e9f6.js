"use strict";(self.webpackChunkmy_tfg_logbook=self.webpackChunkmy_tfg_logbook||[]).push([[3210],{3358:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>l,contentTitle:()=>r,default:()=>c,frontMatter:()=>s,metadata:()=>t,toc:()=>d});const t=JSON.parse('{"id":"First Fine Tune Test/fine_tuning_images_by_RIM-ONE_with_llama_3.2_3B","title":"Testing Fine-Tuning Images by RIM-ONE with Llama 3.2 3B","description":"Introduction","source":"@site/docs/5. First Fine Tune Test/fine_tuning_images_by_RIM-ONE_with_llama_3.2_3B.md","sourceDirName":"5. First Fine Tune Test","slug":"/First Fine Tune Test/fine_tuning_images_by_RIM-ONE_with_llama_3.2_3B","permalink":"/My-TFG-Logbook/es/docs/First Fine Tune Test/fine_tuning_images_by_RIM-ONE_with_llama_3.2_3B","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"sidebar_position":1},"sidebar":"tutorialSidebar","previous":{"title":"Exploring Google Colab Combined with Gemini for Project Use","permalink":"/My-TFG-Logbook/es/docs/Initial Research/exploring_gemini_colab"}}');var a=i(4848),o=i(8453);const s={sidebar_position:1},r="Testing Fine-Tuning Images by RIM-ONE with Llama 3.2 3B",l={},d=[{value:"Introduction",id:"introduction",level:2},{value:"Setting Up the Environment in Google Colab",id:"setting-up-the-environment-in-google-colab",level:2},{value:"Defining the Prompt for the Model",id:"defining-the-prompt-for-the-model",level:2},{value:"Image Preprocessing",id:"image-preprocessing",level:2},{value:"Configuring the Model and Training",id:"configuring-the-model-and-training",level:2},{value:"Testing the Model with a New Image",id:"testing-the-model-with-a-new-image",level:2},{value:"Insights",id:"insights",level:2}];function h(e){const n={code:"code",em:"em",h1:"h1",h2:"h2",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,o.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(n.header,{children:(0,a.jsx)(n.h1,{id:"testing-fine-tuning-images-by-rim-one-with-llama-32-3b",children:"Testing Fine-Tuning Images by RIM-ONE with Llama 3.2 3B"})}),"\n",(0,a.jsx)(n.h2,{id:"introduction",children:"Introduction"}),"\n",(0,a.jsxs)(n.p,{children:["As a continuation of the documentation, noticing that 'skinGPT4' properly works, I will start to perform a ",(0,a.jsx)(n.em,{children:"fine-tuning"})," of the ",(0,a.jsx)(n.strong,{children:"Llama 3.2 Vision"})," model in its 3 billion parameter (3B) version using the ",(0,a.jsx)(n.strong,{children:"RIM-ONE DL"})," dataset. RIM-ONE is a database of retinal images created by researchers at the University of La Laguna (ULL), specifically designed for retina analysis in glaucoma detection. This dataset includes images captured in several Spanish hospitals and is divided into different classes for healthy and glaucoma-diagnosed eyes."]}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.em,{children:(0,a.jsx)(n.strong,{children:"Note: The decision to use the 3B parameter version is because it is a lightweight version and can be tested even on Google Colab."})})}),"\n",(0,a.jsx)(n.h2,{id:"setting-up-the-environment-in-google-colab",children:"Setting Up the Environment in Google Colab"}),"\n",(0,a.jsxs)(n.ol,{children:["\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Upload Dataset to Google Drive"}),":"]}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["Organize the images in Google Drive into a specific folder structure:","\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{children:"partitioned_by_hospital/\n\u2514\u2500\u2500 training_set/\n    \u251c\u2500\u2500 normal/\n    \u2514\u2500\u2500 glaucoma/\n"})}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsxs)(n.li,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Mount Google Drive"}),":"]}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["Use the following code to mount Google Drive and load the dataset into a Pandas ",(0,a.jsx)(n.code,{children:"DataFrame"}),":","\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"from google.colab import drive\nimport os\nimport pandas as pd\n\ndrive.mount('/content/drive')\n\nbase_path = '/content/drive/MyDrive/partitioned_by_hospital/training_set'\nimage_paths = []\nlabels = []\n\n# Load all images in each category without limits\nfor label in ['normal', 'glaucoma']:\n    folder_path = os.path.join(base_path, label)\n    for image_name in os.listdir(folder_path):\n        image_paths.append(os.path.join(folder_path, image_name))\n        labels.append(0 if label == 'normal' else 1)\n\ndf = pd.DataFrame({'image_path': image_paths, 'label': labels})\n"})}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsx)(n.h2,{id:"defining-the-prompt-for-the-model",children:"Defining the Prompt for the Model"}),"\n",(0,a.jsxs)(n.p,{children:["To guide the model in its task, I define a detailed ",(0,a.jsx)(n.em,{children:"prompt"}),' that positions it as a "virtual ophthalmologist" capable of identifying signs of glaucoma in the images:']}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"detailed_prompt = '''\nI am a virtual ophthalmologist specializing in retinal health. I have a retinal image (retinography) that I want to analyze to determine if the patient shows signs of glaucoma or if it is a healthy eye. The retinography shows the optic disc and blood vessels.\nCharacteristics to Identify:\nSuggestive of Glaucoma:\n    - Cup-to-Disc Ratio (C/D ratio): If the cup diameter is large in relation to the disc (C/D ratio > 0.6), it may indicate glaucoma.\n    - Asymmetry between Eyes: Significant differences in the C/D ratio between both eyes can be a risk sign.\n    - Attenuation or Displacement of Blood Vessels: Blood vessels that are displaced or thinned at the edge of the optic disc are characteristic of advanced glaucoma.\n    - Peripapillary Hemorrhages: Small hemorrhages on the margins of the optic disc may indicate glaucomatous damage.\n    - Changes in the Shape or Edge of the Optic Disc: Irregularities or a deeper-than-normal excavation at the edge of the optic disc.\nIndicative of a Healthy Eye:\n    - Normal Cup-to-Disc Ratio: A C/D ratio < 0.5 is generally considered normal.\n    - Symmetry between Both Eyes: Similar cup-to-disc ratios in both eyes reduce the likelihood of glaucoma.\n    - Well-Positioned Blood Vessels: No displacement or thinning at the edge of the optic disc.\n    - Absence of Peripapillary Hemorrhages: No hemorrhages are observed on the margins of the optic disc.\n    - Regular Optic Disc Edge: Sharp edge and normal shape without excessive excavation.\nFinal Evaluation:\nProvide a conclusion as to whether the retinography shows signs compatible with glaucoma, indicating the estimated probability and the parameters on which you base your assessment. If the probability is low, state directly that the image does not present glaucoma due to the low estimated percentage.\n'''\ndf['prompt'] = detailed_prompt\n"})}),"\n",(0,a.jsx)(n.h2,{id:"image-preprocessing",children:"Image Preprocessing"}),"\n",(0,a.jsx)(n.p,{children:"Each image is preprocessed to ensure it is compatible with the model:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"from torchvision import transforms\nfrom PIL import Image\n\ndef preprocess_image(image_path):\n    image = Image.open(image_path).convert(\"RGB\")\n    transform = transforms.Compose([\n        transforms.Resize((224, 224)),\n        transforms.ToTensor(),\n    ])\n    return transform(image).unsqueeze(0)\ndf['image'] = df['image_path'].apply(preprocess_image)\n"})}),"\n",(0,a.jsx)(n.h2,{id:"configuring-the-model-and-training",children:"Configuring the Model and Training"}),"\n",(0,a.jsxs)(n.p,{children:["I load the ",(0,a.jsx)(n.strong,{children:"Llama 3B Vision"})," model and set up training for Colab Free."]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'from transformers import LlamaForCausalLM, LlamaTokenizer, Trainer, TrainingArguments\n\nmodel_name = "meta-llama/Llama-3B-Vision-Instruct"\nmodel = LlamaForCausalLM.from_pretrained(model_name)\ntokenizer = LlamaTokenizer.from_pretrained(model_name)\n\ndef tokenize_function(examples):\n    return tokenizer(examples[\'prompt\'], padding="max_length", truncation=True, max_length=256)\n\ntokenized_dataset = dataset.map(tokenize_function, batched=True)\n\ntraining_args = TrainingArguments(\n    output_dir="./results",\n    evaluation_strategy="epoch",\n    per_device_train_batch_size=1,\n    num_train_epochs=1,\n    save_steps=100,\n    save_total_limit=2,\n    fp16=True,\n    logging_dir="./logs",\n)\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_dataset\n)\n\ntrainer.train()\n'})}),"\n",(0,a.jsx)(n.h2,{id:"testing-the-model-with-a-new-image",children:"Testing the Model with a New Image"}),"\n",(0,a.jsxs)(n.p,{children:["After ",(0,a.jsx)(n.em,{children:"fine-tuning"}),", I test the model with a new image."]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'new_image_path = \'/content/drive/MyDrive/new_retina_image.jpg\'\nimage_tensor = preprocess_image(new_image_path)\n\ninputs = tokenizer(detailed_prompt, return_tensors="pt")\noutputs = model.generate(**inputs)\n\nresponse = tokenizer.decode(outputs[0], skip_special_tokens=True)\nprint("Analysis result:", response)\n'})}),"\n",(0,a.jsx)(n.h2,{id:"insights",children:"Insights"}),"\n",(0,a.jsxs)(n.p,{children:["This section demonstrates how to perform ",(0,a.jsx)(n.em,{children:"fine-tuning"})," on a vision model using a specific dataset like ",(0,a.jsx)(n.strong,{children:"RIM-ONE DL"})," and adapt it to detect signs of glaucoma in retinal images. The use of a detailed ",(0,a.jsx)(n.em,{children:"prompt"}),' allows the model to respond as a "virtual ophthalmologist," providing an exhaustive analysis based on key glaucoma diagnostic parameters.']}),"\n",(0,a.jsx)(n.p,{children:"In the next pages I will be describing the promising results that this first fine-tune does."})]})}function c(e={}){const{wrapper:n}={...(0,o.R)(),...e.components};return n?(0,a.jsx)(n,{...e,children:(0,a.jsx)(h,{...e})}):h(e)}},8453:(e,n,i)=>{i.d(n,{R:()=>s,x:()=>r});var t=i(6540);const a={},o=t.createContext(a);function s(e){const n=t.useContext(o);return t.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function r(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:s(e.components),t.createElement(o.Provider,{value:n},e.children)}}}]);