<?xml version="1.0" encoding="utf-8"?><?xml-stylesheet type="text/xsl" href="atom.xsl"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://edujbarrios.github.io/My-TFG-Logbook/es/blog</id>
    <title>LLMs and Fine Tuning in glaucoma detection Blog</title>
    <updated>2024-11-10T21:03:24.000Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://edujbarrios.github.io/My-TFG-Logbook/es/blog"/>
    <subtitle>LLMs and Fine Tuning in glaucoma detection Blog</subtitle>
    <icon>https://edujbarrios.github.io/My-TFG-Logbook/es/img/favicon.ico</icon>
    <entry>
        <title type="html"><![CDATA[Exploring Medical Diagnostic LLMs: A Comprehensive Guide to Using GitHub's Model Marketplace for Glaucoma Detection in Retinographies]]></title>
        <id>https://edujbarrios.github.io/My-TFG-Logbook/es/blog/using-github-marketplace-for-glaucoma-diagnostics</id>
        <link href="https://edujbarrios.github.io/My-TFG-Logbook/es/blog/using-github-marketplace-for-glaucoma-diagnostics"/>
        <updated>2024-11-10T21:03:24.000Z</updated>
        <summary type="html"><![CDATA[Artificial intelligence (AI) is rapidly evolving in the field of medical diagnostics, particularly with the support of large language models (LLMs) trained to interpret medical images. By utilizing models available on the GitHub Model Marketplace, professionals and developers can test various LLMs on specific tasks, such as analyzing retinographies to detect signs of glaucoma. This guide walks you through setting up a medical diagnostic model from GitHub’s Marketplace to evaluate its performance on glaucoma detection.]]></summary>
        <content type="html"><![CDATA[<p>Artificial intelligence (AI) is rapidly evolving in the field of medical diagnostics, particularly with the support of <strong>large language models (LLMs)</strong> trained to interpret medical images. By utilizing models available on the <strong>GitHub Model Marketplace</strong>, professionals and developers can test various LLMs on specific tasks, such as analyzing retinographies to detect signs of glaucoma. This guide walks you through setting up a medical diagnostic model from GitHub’s Marketplace to evaluate its performance on glaucoma detection.</p>
<p>Additionally, we discuss how these steps can lay the groundwork for potential <strong>fine-tuning</strong>, allowing models to be further optimized for even higher accuracy in specific diagnostic contexts.</p>
<!-- -->
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="introduction">Introduction<a href="https://edujbarrios.github.io/My-TFG-Logbook/es/blog/using-github-marketplace-for-glaucoma-diagnostics#introduction" class="hash-link" aria-label="Enlace directo al Introduction" title="Enlace directo al Introduction">​</a></h2>
<p>As healthcare progresses, the role of AI in diagnostics—especially in <strong>medical imaging</strong>—is becoming indispensable. With access to models that can analyze retinographies, healthcare providers have new tools that complement their expertise, enhancing accuracy and response times.</p>
<p>GitHub's Model Marketplace offers a broad selection of pre-trained LLMs, including models fine-tuned for medical diagnostics. These models can be evaluated on specific tasks to understand their effectiveness in real-world medical applications and explore where future <strong>fine-tuning</strong> could provide further enhancements.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="step-by-step-guide-to-using-github-model-marketplace">Step-by-Step Guide to Using GitHub Model Marketplace<a href="https://edujbarrios.github.io/My-TFG-Logbook/es/blog/using-github-marketplace-for-glaucoma-diagnostics#step-by-step-guide-to-using-github-model-marketplace" class="hash-link" aria-label="Enlace directo al Step-by-Step Guide to Using GitHub Model Marketplace" title="Enlace directo al Step-by-Step Guide to Using GitHub Model Marketplace">​</a></h2>
<p>The GitHub Model Marketplace provides access to a variety of models tailored for different diagnostic tasks. In this guide, we’ll demonstrate how to use these models to analyze a retinography and assess their diagnostic capabilities for glaucoma detection.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="step-1-finding-a-model-in-the-marketplace">Step 1: Finding a Model in the Marketplace<a href="https://edujbarrios.github.io/My-TFG-Logbook/es/blog/using-github-marketplace-for-glaucoma-diagnostics#step-1-finding-a-model-in-the-marketplace" class="hash-link" aria-label="Enlace directo al Step 1: Finding a Model in the Marketplace" title="Enlace directo al Step 1: Finding a Model in the Marketplace">​</a></h3>
<ol>
<li>Go to the <strong>GitHub Model Marketplace</strong> and search for relevant medical diagnostic models, such as those trained on retinography analysis.</li>
<li>Select a model that suits your diagnostic needs. Review model descriptions to ensure it has been fine-tuned on medical imaging data specific to retinal images, which is essential for reliable results.</li>
</ol>
<p>This first step allows you to choose a model that is already partially prepared for diagnostic tasks in ophthalmology, although these models may benefit from additional fine-tuning in the future for even more accurate results.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="step-2-setting-up-your-environment">Step 2: Setting Up Your Environment<a href="https://edujbarrios.github.io/My-TFG-Logbook/es/blog/using-github-marketplace-for-glaucoma-diagnostics#step-2-setting-up-your-environment" class="hash-link" aria-label="Enlace directo al Step 2: Setting Up Your Environment" title="Enlace directo al Step 2: Setting Up Your Environment">​</a></h3>
<p>To get started, make sure you have the necessary libraries installed, such as <code>torch</code>, <code>transformers</code>, and <code>PIL</code> for image processing. You can install them using:</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">pip install torch transformers pillow</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copiar código" title="Copiar" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>Setting up a consistent environment ensures reproducibility and allows for seamless testing across multiple models.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="step-3-loading-and-testing-the-model">Step 3: Loading and Testing the Model<a href="https://edujbarrios.github.io/My-TFG-Logbook/es/blog/using-github-marketplace-for-glaucoma-diagnostics#step-3-loading-and-testing-the-model" class="hash-link" aria-label="Enlace directo al Step 3: Loading and Testing the Model" title="Enlace directo al Step 3: Loading and Testing the Model">​</a></h3>
<p>The next step is to load the chosen model from the GitHub Model Marketplace and apply it to a retinography image:</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">from</span><span class="token plain"> transformers </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">import</span><span class="token plain"> AutoModelForImageClassification</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> AutoFeatureExtractor</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">from</span><span class="token plain"> PIL </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">import</span><span class="token plain"> Image</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">import</span><span class="token plain"> torch</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token comment" style="color:rgb(98, 114, 164)"># Load model from GitHub Model Marketplace</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">model_name </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">"your-chosen-model"</span><span class="token plain">  </span><span class="token comment" style="color:rgb(98, 114, 164)"># Replace with the model ID from the marketplace</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">model </span><span class="token operator">=</span><span class="token plain"> AutoModelForImageClassification</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">from_pretrained</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">model_name</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">feature_extractor </span><span class="token operator">=</span><span class="token plain"> AutoFeatureExtractor</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">from_pretrained</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">model_name</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token comment" style="color:rgb(98, 114, 164)"># Load a retinography image</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">image </span><span class="token operator">=</span><span class="token plain"> Image</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token builtin" style="color:rgb(189, 147, 249)">open</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token string" style="color:rgb(255, 121, 198)">"path_to_retinography_image.jpg"</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">inputs </span><span class="token operator">=</span><span class="token plain"> feature_extractor</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">images</span><span class="token operator">=</span><span class="token plain">image</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> return_tensors</span><span class="token operator">=</span><span class="token string" style="color:rgb(255, 121, 198)">"pt"</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token comment" style="color:rgb(98, 114, 164)"># Make predictions</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">with</span><span class="token plain"> torch</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">no_grad</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    outputs </span><span class="token operator">=</span><span class="token plain"> model</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token operator">**</span><span class="token plain">inputs</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    predictions </span><span class="token operator">=</span><span class="token plain"> torch</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">nn</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">functional</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">softmax</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">outputs</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">logits</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> dim</span><span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">print</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token string" style="color:rgb(255, 121, 198)">"Prediction results:"</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> predictions</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copiar código" title="Copiar" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>This step allows you to assess the model's baseline performance, which could be refined with future fine-tuning tailored to glaucoma detection.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="step-4-setting-a-role-specific-prompt">Step 4: Setting a Role-Specific Prompt<a href="https://edujbarrios.github.io/My-TFG-Logbook/es/blog/using-github-marketplace-for-glaucoma-diagnostics#step-4-setting-a-role-specific-prompt" class="hash-link" aria-label="Enlace directo al Step 4: Setting a Role-Specific Prompt" title="Enlace directo al Step 4: Setting a Role-Specific Prompt">​</a></h3>
<p>For a more accurate assessment, defining a specific role that aligns with the diagnostic goal can direct the model’s focus. In this case, we’ll assume the role of an <strong>ophthalmologist focusing on glaucoma detection</strong>:</p>
<ul>
<li>Adjust the input prompt or model configuration to specify: <strong>"As an ophthalmologist specializing in glaucoma detection, analyze this retinography for signs of glaucoma. Pay special attention to optic nerve cupping, retinal nerve fiber layer thinning, and characteristic glaucomatous changes that could indicate early-stage or advanced glaucoma."</strong></li>
</ul>
<p>This prompt introduces role-specific expertise, helping the model prioritize clinically relevant features for glaucoma, such as optic nerve health and retinal changes.</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token comment" style="color:rgb(98, 114, 164)"># Example prompt setting (if supported by the model or input setup)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">prompt </span><span class="token operator">=</span><span class="token plain"> </span><span class="token string" style="color:rgb(255, 121, 198)">"As an ophthalmologist specializing in glaucoma detection, assess this retinography for optic nerve cupping, retinal thinning, and glaucomatous changes."</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token comment" style="color:rgb(98, 114, 164)"># Adjust model inputs or preprocessing as required by the model's API.</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copiar código" title="Copiar" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>This step not only adds clarity to the model’s task but also opens up the possibility of fine-tuning. By collecting results from multiple cases, you can refine prompts and data inputs for better outcomes, especially for highly specific diagnostic tasks.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="step-5-evaluating-model-performance">Step 5: Evaluating Model Performance<a href="https://edujbarrios.github.io/My-TFG-Logbook/es/blog/using-github-marketplace-for-glaucoma-diagnostics#step-5-evaluating-model-performance" class="hash-link" aria-label="Enlace directo al Step 5: Evaluating Model Performance" title="Enlace directo al Step 5: Evaluating Model Performance">​</a></h3>
<p>Once you have the model configured, evaluate its performance with metrics like <strong>accuracy</strong>, <strong>sensitivity</strong>, and <strong>specificity</strong> to determine its effectiveness in detecting glaucoma.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="potential-for-fine-tuning">Potential for Fine-Tuning<a href="https://edujbarrios.github.io/My-TFG-Logbook/es/blog/using-github-marketplace-for-glaucoma-diagnostics#potential-for-fine-tuning" class="hash-link" aria-label="Enlace directo al Potential for Fine-Tuning" title="Enlace directo al Potential for Fine-Tuning">​</a></h3>
<p>With diagnostic tasks as specialized as glaucoma detection, there is significant potential for <strong>fine-tuning</strong>. Fine-tuning involves training the model on a dataset specifically curated for glaucoma or other ophthalmologic conditions, allowing it to learn patterns and markers associated with these diseases in detail.</p>
<p>By fine-tuning on a large dataset of labeled retinographies, for instance, the model can learn nuanced patterns that may indicate early-stage glaucoma. Fine-tuning could be conducted with frameworks such as <strong>PyTorch</strong> or <strong>TensorFlow</strong>, and would require a labeled dataset of glaucoma-positive and negative cases for best results.</p>
<p>Fine-tuning steps could involve:</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">from</span><span class="token plain"> transformers </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">import</span><span class="token plain"> Trainer</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> TrainingArguments</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token comment" style="color:rgb(98, 114, 164)"># Training parameters</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">training_args </span><span class="token operator">=</span><span class="token plain"> TrainingArguments</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    output_dir</span><span class="token operator">=</span><span class="token string" style="color:rgb(255, 121, 198)">"./results"</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    num_train_epochs</span><span class="token operator">=</span><span class="token number">3</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    per_device_train_batch_size</span><span class="token operator">=</span><span class="token number">8</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    logging_dir</span><span class="token operator">=</span><span class="token string" style="color:rgb(255, 121, 198)">"./logs"</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token comment" style="color:rgb(98, 114, 164)"># Set up Trainer with the labeled retinography dataset</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">trainer </span><span class="token operator">=</span><span class="token plain"> Trainer</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    model</span><span class="token operator">=</span><span class="token plain">model</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    args</span><span class="token operator">=</span><span class="token plain">training_args</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    train_dataset</span><span class="token operator">=</span><span class="token plain">glaucoma_dataset</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain">  </span><span class="token comment" style="color:rgb(98, 114, 164)"># replace with your glaucoma-specific dataset</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">trainer</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">train</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copiar código" title="Copiar" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>This added step not only enhances diagnostic accuracy but also customizes the model for specific needs in glaucoma detection, potentially aiding in the early diagnosis of this sight-threatening condition.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="best-practices">Best Practices<a href="https://edujbarrios.github.io/My-TFG-Logbook/es/blog/using-github-marketplace-for-glaucoma-diagnostics#best-practices" class="hash-link" aria-label="Enlace directo al Best Practices" title="Enlace directo al Best Practices">​</a></h3>
<ul>
<li><strong>Data Preparation</strong>: Ensure the input images are high quality and properly preprocessed for optimal accuracy.</li>
<li><strong>Prompt Customization</strong>: Tailor prompts to emphasize specific indicators of glaucoma in retinography images.</li>
<li><strong>Performance Metrics</strong>: Use relevant metrics like <strong>accuracy</strong>, <strong>sensitivity</strong>, and <strong>specificity</strong> to assess model reliability in detecting glaucoma.</li>
<li><strong>Iterative Fine-Tuning</strong>: As more labeled data becomes available, consider additional rounds of fine-tuning for increased diagnostic precision.</li>
</ul>
<div class="theme-admonition theme-admonition-tip admonition_xJq3 alert alert--success"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 12 16"><path fill-rule="evenodd" d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"></path></svg></span>tip</div><div class="admonitionContent_BuS1"><p>Utilizing GitHub's Model Marketplace lets you experiment with a variety of models, helping you find the most effective options for specific diagnostic tasks, such as glaucoma detection.</p></div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="conclusion">Conclusion<a href="https://edujbarrios.github.io/My-TFG-Logbook/es/blog/using-github-marketplace-for-glaucoma-diagnostics#conclusion" class="hash-link" aria-label="Enlace directo al Conclusion" title="Enlace directo al Conclusion">​</a></h2>
<p>Testing LLMs from the GitHub Model Marketplace allows healthcare providers and AI developers to explore state-of-the-art models in medical diagnostics. With easy access to these tools, professionals can enhance diagnostic precision, adding valuable support to traditional medical practices. Fine-tuning opportunities also mean these models can be continually improved, offering the potential for ongoing advancements in glaucoma detection and beyond.</p>
<hr>]]></content>
        <author>
            <name>Eduardo José Barrios García</name>
            <uri>https://github.com/edujbarrios</uri>
        </author>
        <category label="LLMs" term="LLMs"/>
        <category label="GitHub Marketplace" term="GitHub Marketplace"/>
        <category label="medical imaging" term="medical imaging"/>
        <category label="retinography" term="retinography"/>
        <category label="glaucoma detection" term="glaucoma detection"/>
        <category label="AI" term="AI"/>
        <category label="fine-tuning" term="fine-tuning"/>
    </entry>
    <entry>
        <title type="html"><![CDATA[Leveraging Neural Networks and Fine-Tuning in Large Language Models: A Synergy for Enhanced AI Capabilities]]></title>
        <id>https://edujbarrios.github.io/My-TFG-Logbook/es/blog/neural-networks-fine-tuning-llms</id>
        <link href="https://edujbarrios.github.io/My-TFG-Logbook/es/blog/neural-networks-fine-tuning-llms"/>
        <updated>2024-11-10T21:03:24.000Z</updated>
        <summary type="html"><![CDATA[In the realm of artificial intelligence, neural networks and fine-tuning are fundamental components that drive the capabilities of large language models (LLMs), like GPT-4 and beyond. The paper “LLaMA-Factory: Efficient Training Techniques for Large Language Models” delves into methods that optimize training, reduce costs, and improve the performance of LLMs. This article explores the interplay of neural networks, fine-tuning, and LLMs, along with practical insights into model improvement with references to the LLaMA-Factory GitHub repository.]]></summary>
        <content type="html"><![CDATA[<p>In the realm of artificial intelligence, <strong>neural networks</strong> and <strong>fine-tuning</strong> are fundamental components that drive the capabilities of <strong>large language models (LLMs)</strong>, like GPT-4 and beyond. The paper “<a href="https://arxiv.org/abs/2403.13372" target="_blank" rel="noopener noreferrer">LLaMA-Factory: Efficient Training Techniques for Large Language Models</a>” delves into methods that optimize training, reduce costs, and improve the performance of LLMs. This article explores the interplay of neural networks, fine-tuning, and LLMs, along with practical insights into model improvement with references to the <a href="https://github.com/hiyouga/LLaMA-Factory" target="_blank" rel="noopener noreferrer">LLaMA-Factory GitHub repository</a>.</p>
<!-- -->
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="introduction">Introduction<a href="https://edujbarrios.github.io/My-TFG-Logbook/es/blog/neural-networks-fine-tuning-llms#introduction" class="hash-link" aria-label="Enlace directo al Introduction" title="Enlace directo al Introduction">​</a></h2>
<p>The development of LLMs has revolutionized natural language processing, enabling applications from chatbots to sophisticated data analysis tools. At the core of these models lies the intricate architecture of <strong>neural networks</strong>, fine-tuned over vast datasets to produce meaningful responses. Fine-tuning not only enhances model capabilities in specific domains but also boosts performance in tasks that require a high degree of accuracy, such as <strong>medical diagnostics</strong> and <strong>customer support</strong>. The techniques discussed in LLaMA-Factory provide a blueprint for making these models more efficient and accessible.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="understanding-neural-networks-and-fine-tuning">Understanding Neural Networks and Fine-Tuning<a href="https://edujbarrios.github.io/My-TFG-Logbook/es/blog/neural-networks-fine-tuning-llms#understanding-neural-networks-and-fine-tuning" class="hash-link" aria-label="Enlace directo al Understanding Neural Networks and Fine-Tuning" title="Enlace directo al Understanding Neural Networks and Fine-Tuning">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="neural-networks-the-foundation-of-llms">Neural Networks: The Foundation of LLMs<a href="https://edujbarrios.github.io/My-TFG-Logbook/es/blog/neural-networks-fine-tuning-llms#neural-networks-the-foundation-of-llms" class="hash-link" aria-label="Enlace directo al Neural Networks: The Foundation of LLMs" title="Enlace directo al Neural Networks: The Foundation of LLMs">​</a></h3>
<p>Neural networks are the backbone of AI models. These layered networks simulate the human brain, allowing models to recognize complex patterns in data. LLMs, a type of neural network, use vast architectures—often with millions or billions of parameters. Through <strong>transformer-based architectures</strong>, LLMs excel in understanding and generating human language.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="fine-tuning-for-task-specific-performance">Fine-Tuning for Task-Specific Performance<a href="https://edujbarrios.github.io/My-TFG-Logbook/es/blog/neural-networks-fine-tuning-llms#fine-tuning-for-task-specific-performance" class="hash-link" aria-label="Enlace directo al Fine-Tuning for Task-Specific Performance" title="Enlace directo al Fine-Tuning for Task-Specific Performance">​</a></h3>
<p>Fine-tuning refers to the process of training a pre-trained model on a specialized dataset. This additional training helps the model focus on particular features of the data, enhancing its ability to perform specific tasks. For instance, fine-tuning can transform a general-purpose language model into an expert in a given field, like <strong>medical language processing</strong> or <strong>technical documentation</strong>. By adapting an LLM to understand unique vocabulary and patterns, fine-tuning enables more accurate and reliable outputs.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="key-benefits-of-fine-tuning-in-llms">Key Benefits of Fine-Tuning in LLMs<a href="https://edujbarrios.github.io/My-TFG-Logbook/es/blog/neural-networks-fine-tuning-llms#key-benefits-of-fine-tuning-in-llms" class="hash-link" aria-label="Enlace directo al Key Benefits of Fine-Tuning in LLMs" title="Enlace directo al Key Benefits of Fine-Tuning in LLMs">​</a></h4>
<ul>
<li><strong>Domain-Specific Accuracy</strong>: Fine-tuning adjusts model weights to better handle data nuances in a given domain.</li>
<li><strong>Resource Efficiency</strong>: Leveraging pre-trained models reduces the computational resources required for training.</li>
<li><strong>Scalability</strong>: Fine-tuning allows models to be customized for multiple tasks without re-training from scratch.</li>
</ul>
<div class="theme-admonition theme-admonition-tip admonition_xJq3 alert alert--success"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 12 16"><path fill-rule="evenodd" d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"></path></svg></span>tip</div><div class="admonitionContent_BuS1"><p>The LLaMA-Factory paper introduces efficient fine-tuning techniques that reduce computational requirements, making large models more accessible for research and industry applications.</p></div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="integrating-neural-networks-with-llms-practical-applications">Integrating Neural Networks with LLMs: Practical Applications<a href="https://edujbarrios.github.io/My-TFG-Logbook/es/blog/neural-networks-fine-tuning-llms#integrating-neural-networks-with-llms-practical-applications" class="hash-link" aria-label="Enlace directo al Integrating Neural Networks with LLMs: Practical Applications" title="Enlace directo al Integrating Neural Networks with LLMs: Practical Applications">​</a></h2>
<p>By fine-tuning neural networks within LLMs, we unlock new possibilities across sectors. For instance, a fine-tuned LLM trained on a dataset of <strong>medical case studies</strong> can assist in diagnostic processes, helping clinicians identify patterns and anomalies. This is particularly relevant in fields where domain-specific expertise is critical, and time is a crucial factor.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="code-example-fine-tuning-a-language-model-with-transformers-and-pytorch">Code Example: Fine-Tuning a Language Model with Transformers and PyTorch<a href="https://edujbarrios.github.io/My-TFG-Logbook/es/blog/neural-networks-fine-tuning-llms#code-example-fine-tuning-a-language-model-with-transformers-and-pytorch" class="hash-link" aria-label="Enlace directo al Code Example: Fine-Tuning a Language Model with Transformers and PyTorch" title="Enlace directo al Code Example: Fine-Tuning a Language Model with Transformers and PyTorch">​</a></h3>
<p>Leveraging the <a href="https://github.com/hiyouga/LLaMA-Factory" target="_blank" rel="noopener noreferrer">LLaMA-Factory repository</a>, we can fine-tune an LLM using efficient training practices as outlined in the research. Here’s an example:</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">from</span><span class="token plain"> transformers </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">import</span><span class="token plain"> AutoModelForCausalLM</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> Trainer</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> TrainingArguments</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">import</span><span class="token plain"> torch</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token comment" style="color:rgb(98, 114, 164)"># Load a pre-trained LLM model, such as LLaMA or GPT-style models</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">model </span><span class="token operator">=</span><span class="token plain"> AutoModelForCausalLM</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">from_pretrained</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token string" style="color:rgb(255, 121, 198)">"pretrained-llm"</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token comment" style="color:rgb(98, 114, 164)"># Define training parameters</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">training_args </span><span class="token operator">=</span><span class="token plain"> TrainingArguments</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    output_dir</span><span class="token operator">=</span><span class="token string" style="color:rgb(255, 121, 198)">"./results"</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    num_train_epochs</span><span class="token operator">=</span><span class="token number">3</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    per_device_train_batch_size</span><span class="token operator">=</span><span class="token number">4</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    warmup_steps</span><span class="token operator">=</span><span class="token number">500</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    weight_decay</span><span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    logging_dir</span><span class="token operator">=</span><span class="token string" style="color:rgb(255, 121, 198)">"./logs"</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token comment" style="color:rgb(98, 114, 164)"># Assuming a domain-specific dataset (e.g., medical texts)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">trainer </span><span class="token operator">=</span><span class="token plain"> Trainer</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    model</span><span class="token operator">=</span><span class="token plain">model</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    args</span><span class="token operator">=</span><span class="token plain">training_args</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    train_dataset</span><span class="token operator">=</span><span class="token plain">domain_specific_dataset</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">trainer</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">train</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copiar código" title="Copiar" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>In this example, we fine-tune a pre-trained language model using <strong>Transformers</strong> and <strong>PyTorch</strong>. Training arguments, such as <code>num_train_epochs</code> and <code>weight_decay</code>, are critical in managing model performance and computational efficiency, as explored in the LLaMA-Factory paper.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="future-implications-of-fine-tuning-llms">Future Implications of Fine-Tuning LLMs<a href="https://edujbarrios.github.io/My-TFG-Logbook/es/blog/neural-networks-fine-tuning-llms#future-implications-of-fine-tuning-llms" class="hash-link" aria-label="Enlace directo al Future Implications of Fine-Tuning LLMs" title="Enlace directo al Future Implications of Fine-Tuning LLMs">​</a></h2>
<p>The synergy between neural networks and fine-tuning in LLMs could lead to significant advancements in various industries:</p>
<ul>
<li><strong>Healthcare</strong>: LLMs fine-tuned on medical literature and patient data could support diagnostics and personalized treatment recommendations.</li>
<li><strong>Legal and Financial Services</strong>: Fine-tuned models could provide tailored responses and insights, analyzing legal documents or financial statements.</li>
<li><strong>Education</strong>: LLMs could generate custom educational content and adapt to individual learning styles.</li>
</ul>
<p>By building on the research in LLaMA-Factory, developers can create LLMs that are more efficient, accessible, and aligned with domain-specific needs.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="conclusion">Conclusion<a href="https://edujbarrios.github.io/My-TFG-Logbook/es/blog/neural-networks-fine-tuning-llms#conclusion" class="hash-link" aria-label="Enlace directo al Conclusion" title="Enlace directo al Conclusion">​</a></h2>
<p>Neural networks and fine-tuning have brought LLMs to the forefront of AI advancements, as highlighted in the <strong>LLaMA-Factory</strong> paper. By focusing on efficient training techniques, we can harness the full potential of LLMs across sectors, making them more accessible for specialized tasks. Fine-tuning remains a vital part of this development, unlocking the capability of LLMs to perform precise and domain-specific tasks.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="references">References<a href="https://edujbarrios.github.io/My-TFG-Logbook/es/blog/neural-networks-fine-tuning-llms#references" class="hash-link" aria-label="Enlace directo al References" title="Enlace directo al References">​</a></h2>
<ol>
<li>
<p>Hiyouga, L., et al. (2024). <a href="https://arxiv.org/abs/2403.13372" target="_blank" rel="noopener noreferrer">"LLaMA-Factory: Efficient Training Techniques for Large Language Models"</a>. <em>arXiv</em>.</p>
</li>
<li>
<p>GitHub Repository for LLaMA-Factory. (2024). Available at: <a href="https://github.com/hiyouga/LLaMA-Factory" target="_blank" rel="noopener noreferrer">https://github.com/hiyouga/LLaMA-Factory</a></p>
</li>
</ol>]]></content>
        <author>
            <name>Eduardo José Barrios García</name>
            <uri>https://github.com/edujbarrios</uri>
        </author>
        <category label="Neural networks" term="Neural networks"/>
        <category label="fine-tuning" term="fine-tuning"/>
        <category label="LLMs" term="LLMs"/>
        <category label="AI" term="AI"/>
        <category label="deep learning" term="deep learning"/>
        <category label="transformers" term="transformers"/>
        <category label="Python" term="Python"/>
    </entry>
    <entry>
        <title type="html"><![CDATA[Enhancing Medical Diagnostics with Prompt Engineering: A Deep Dive into AI Accuracy and Potential]]></title>
        <id>https://edujbarrios.github.io/My-TFG-Logbook/es/blog/prompt-engineering-medical-diagnostics</id>
        <link href="https://edujbarrios.github.io/My-TFG-Logbook/es/blog/prompt-engineering-medical-diagnostics"/>
        <updated>2024-11-10T21:03:24.000Z</updated>
        <summary type="html"><![CDATA[Medical imaging diagnostics are one of the most promising fields for artificial intelligence applications. With advancements in prompt engineering and fine-tuning models, AI is poised to revolutionize diagnostics, making them faster and, potentially, more accurate. In this article, we’ll explore how prompt engineering and AI tools, including fine-tuning and Python, can impact the field of medical diagnostics.]]></summary>
        <content type="html"><![CDATA[<p>Medical imaging diagnostics are one of the most promising fields for artificial intelligence applications. With advancements in <strong>prompt engineering</strong> and <strong>fine-tuning models</strong>, AI is poised to revolutionize diagnostics, making them faster and, potentially, more accurate. In this article, we’ll explore how prompt engineering and AI tools, including fine-tuning and Python, can impact the field of medical diagnostics.</p>
<!-- -->
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="introduction">Introduction<a href="https://edujbarrios.github.io/My-TFG-Logbook/es/blog/prompt-engineering-medical-diagnostics#introduction" class="hash-link" aria-label="Enlace directo al Introduction" title="Enlace directo al Introduction">​</a></h2>
<p>Modern healthcare relies heavily on accurate diagnostic tools, especially in <strong>medical imaging</strong> fields like radiology, MRI, and CT scans. AI-driven tools can assist medical professionals by identifying patterns and potential issues that might otherwise go unnoticed. But the real breakthrough lies in <strong>prompt engineering</strong>, where tailored prompts can guide AI models to make more precise predictions.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="what-is-prompt-engineering">What is Prompt Engineering?<a href="https://edujbarrios.github.io/My-TFG-Logbook/es/blog/prompt-engineering-medical-diagnostics#what-is-prompt-engineering" class="hash-link" aria-label="Enlace directo al What is Prompt Engineering?" title="Enlace directo al What is Prompt Engineering?">​</a></h2>
<p>Prompt engineering is the art and science of designing inputs for AI models to maximize their effectiveness. In the context of medical diagnostics, a well-crafted prompt can help an AI model focus on specific features in an image, such as abnormalities or signs of disease. For example, a prompt could instruct the model to "identify and categorize any growths that resemble tumors in this CT scan," thereby streamlining the diagnostic process.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="key-benefits-of-prompt-engineering-in-medical-imaging">Key Benefits of Prompt Engineering in Medical Imaging<a href="https://edujbarrios.github.io/My-TFG-Logbook/es/blog/prompt-engineering-medical-diagnostics#key-benefits-of-prompt-engineering-in-medical-imaging" class="hash-link" aria-label="Enlace directo al Key Benefits of Prompt Engineering in Medical Imaging" title="Enlace directo al Key Benefits of Prompt Engineering in Medical Imaging">​</a></h3>
<ul>
<li><strong>Increased Accuracy</strong>: A targeted prompt can help narrow down the AI's focus, leading to higher diagnostic accuracy.</li>
<li><strong>Consistency in Diagnostics</strong>: Human error is reduced as AI provides a consistent second opinion.</li>
<li><strong>Speed</strong>: Prompt engineering allows for quicker diagnostics, enabling faster patient response times.</li>
</ul>
<div class="theme-admonition theme-admonition-tip admonition_xJq3 alert alert--success"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 12 16"><path fill-rule="evenodd" d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"></path></svg></span>tip</div><div class="admonitionContent_BuS1"><p>AI-driven tools in medical imaging could serve as an additional diagnostic layer, providing insights that might take years of experience for a human specialist to acquire.</p></div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="the-role-of-fine-tuning-for-improved-diagnostics">The Role of Fine-Tuning for Improved Diagnostics<a href="https://edujbarrios.github.io/My-TFG-Logbook/es/blog/prompt-engineering-medical-diagnostics#the-role-of-fine-tuning-for-improved-diagnostics" class="hash-link" aria-label="Enlace directo al The Role of Fine-Tuning for Improved Diagnostics" title="Enlace directo al The Role of Fine-Tuning for Improved Diagnostics">​</a></h2>
<p>While prompt engineering is essential, <strong>fine-tuning</strong> plays an equally critical role. Fine-tuning involves training a pre-existing AI model on a specific dataset to improve its performance in a particular domain—like medical imaging. With tools such as <strong>PyTorch</strong> and <strong>TensorFlow</strong>, fine-tuning models for specific medical tasks has become more accessible.</p>
<p>For instance, a model can be fine-tuned on a dataset of MRI scans to recognize early signs of <strong>Alzheimer's disease</strong>. By continuously refining the model with relevant data, it becomes more adept at spotting nuanced patterns that might indicate disease progression.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="fine-tuning-in-practice">Fine-Tuning in Practice<a href="https://edujbarrios.github.io/My-TFG-Logbook/es/blog/prompt-engineering-medical-diagnostics#fine-tuning-in-practice" class="hash-link" aria-label="Enlace directo al Fine-Tuning in Practice" title="Enlace directo al Fine-Tuning in Practice">​</a></h3>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#F8F8F2;background-color:#282A36"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">from</span><span class="token plain"> transformers </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">import</span><span class="token plain"> AutoModelForImageClassification</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> Trainer</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"> TrainingArguments</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">import</span><span class="token plain"> torch</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token comment" style="color:rgb(98, 114, 164)"># Load a pre-trained model and fine-tune it</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">model </span><span class="token operator">=</span><span class="token plain"> AutoModelForImageClassification</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">from_pretrained</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token string" style="color:rgb(255, 121, 198)">"pretrained-model"</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token comment" style="color:rgb(98, 114, 164)"># Training parameters</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">training_args </span><span class="token operator">=</span><span class="token plain"> TrainingArguments</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    output_dir</span><span class="token operator">=</span><span class="token string" style="color:rgb(255, 121, 198)">"./results"</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    num_train_epochs</span><span class="token operator">=</span><span class="token number">3</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    per_device_train_batch_size</span><span class="token operator">=</span><span class="token number">8</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token comment" style="color:rgb(98, 114, 164)"># Fine-tune on a medical imaging dataset</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">trainer </span><span class="token operator">=</span><span class="token plain"> Trainer</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    model</span><span class="token operator">=</span><span class="token plain">model</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    args</span><span class="token operator">=</span><span class="token plain">training_args</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    train_dataset</span><span class="token operator">=</span><span class="token plain">medical_imaging_dataset</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">trainer</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">train</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copiar código" title="Copiar" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>]]></content>
        <author>
            <name>Eduardo José Barrios García</name>
            <uri>https://github.com/edujbarrios</uri>
        </author>
        <category label="Prompt-engineering" term="Prompt-engineering"/>
        <category label="medicine" term="medicine"/>
        <category label="AI" term="AI"/>
        <category label="medical imaging" term="medical imaging"/>
        <category label="fine-tuning" term="fine-tuning"/>
        <category label="Python" term="Python"/>
    </entry>
</feed>