<?xml version="1.0" encoding="utf-8"?><?xml-stylesheet type="text/xsl" href="rss.xsl"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>LLMs and Fine Tuning in glaucoma detection Blog</title>
        <link>https://edujbarrios.github.io/My-TFG-Logbook/es/blog</link>
        <description>LLMs and Fine Tuning in glaucoma detection Blog</description>
        <lastBuildDate>Thu, 07 Nov 2024 14:05:56 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>es</language>
        <item>
            <title><![CDATA[Leveraging Neural Networks and Fine-Tuning in Large Language Models: A Synergy for Enhanced AI Capabilities]]></title>
            <link>https://edujbarrios.github.io/My-TFG-Logbook/es/blog/neural-networks-fine-tuning-llms</link>
            <guid>https://edujbarrios.github.io/My-TFG-Logbook/es/blog/neural-networks-fine-tuning-llms</guid>
            <pubDate>Thu, 07 Nov 2024 14:05:56 GMT</pubDate>
            <description><![CDATA[In the realm of artificial intelligence, neural networks and fine-tuning are fundamental components that drive the capabilities of large language models (LLMs), like GPT-4 and beyond. The paper “LLaMA-Factory: Efficient Training Techniques for Large Language Models” delves into methods that optimize training, reduce costs, and improve the performance of LLMs. This article explores the interplay of neural networks, fine-tuning, and LLMs, along with practical insights into model improvement with references to the LLaMA-Factory GitHub repository.]]></description>
            <content:encoded><![CDATA[<p>In the realm of artificial intelligence, <strong>neural networks</strong> and <strong>fine-tuning</strong> are fundamental components that drive the capabilities of <strong>large language models (LLMs)</strong>, like GPT-4 and beyond. The paper “<a href="https://arxiv.org/abs/2403.13372" target="_blank" rel="noopener noreferrer">LLaMA-Factory: Efficient Training Techniques for Large Language Models</a>” delves into methods that optimize training, reduce costs, and improve the performance of LLMs. This article explores the interplay of neural networks, fine-tuning, and LLMs, along with practical insights into model improvement with references to the <a href="https://github.com/hiyouga/LLaMA-Factory" target="_blank" rel="noopener noreferrer">LLaMA-Factory GitHub repository</a>.</p>
<!-- -->
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="introduction">Introduction<a href="https://edujbarrios.github.io/My-TFG-Logbook/es/blog/neural-networks-fine-tuning-llms#introduction" class="hash-link" aria-label="Enlace directo al Introduction" title="Enlace directo al Introduction">​</a></h2>
<p>The development of LLMs has revolutionized natural language processing, enabling applications from chatbots to sophisticated data analysis tools. At the core of these models lies the intricate architecture of <strong>neural networks</strong>, fine-tuned over vast datasets to produce meaningful responses. Fine-tuning not only enhances model capabilities in specific domains but also boosts performance in tasks that require a high degree of accuracy, such as <strong>medical diagnostics</strong> and <strong>customer support</strong>. The techniques discussed in LLaMA-Factory provide a blueprint for making these models more efficient and accessible.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="understanding-neural-networks-and-fine-tuning">Understanding Neural Networks and Fine-Tuning<a href="https://edujbarrios.github.io/My-TFG-Logbook/es/blog/neural-networks-fine-tuning-llms#understanding-neural-networks-and-fine-tuning" class="hash-link" aria-label="Enlace directo al Understanding Neural Networks and Fine-Tuning" title="Enlace directo al Understanding Neural Networks and Fine-Tuning">​</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="neural-networks-the-foundation-of-llms">Neural Networks: The Foundation of LLMs<a href="https://edujbarrios.github.io/My-TFG-Logbook/es/blog/neural-networks-fine-tuning-llms#neural-networks-the-foundation-of-llms" class="hash-link" aria-label="Enlace directo al Neural Networks: The Foundation of LLMs" title="Enlace directo al Neural Networks: The Foundation of LLMs">​</a></h3>
<p>Neural networks are the backbone of AI models. These layered networks simulate the human brain, allowing models to recognize complex patterns in data. LLMs, a type of neural network, use vast architectures—often with millions or billions of parameters. Through <strong>transformer-based architectures</strong>, LLMs excel in understanding and generating human language.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="fine-tuning-for-task-specific-performance">Fine-Tuning for Task-Specific Performance<a href="https://edujbarrios.github.io/My-TFG-Logbook/es/blog/neural-networks-fine-tuning-llms#fine-tuning-for-task-specific-performance" class="hash-link" aria-label="Enlace directo al Fine-Tuning for Task-Specific Performance" title="Enlace directo al Fine-Tuning for Task-Specific Performance">​</a></h3>
<p>Fine-tuning refers to the process of training a pre-trained model on a specialized dataset. This additional training helps the model focus on particular features of the data, enhancing its ability to perform specific tasks. For instance, fine-tuning can transform a general-purpose language model into an expert in a given field, like <strong>medical language processing</strong> or <strong>technical documentation</strong>. By adapting an LLM to understand unique vocabulary and patterns, fine-tuning enables more accurate and reliable outputs.</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="key-benefits-of-fine-tuning-in-llms">Key Benefits of Fine-Tuning in LLMs<a href="https://edujbarrios.github.io/My-TFG-Logbook/es/blog/neural-networks-fine-tuning-llms#key-benefits-of-fine-tuning-in-llms" class="hash-link" aria-label="Enlace directo al Key Benefits of Fine-Tuning in LLMs" title="Enlace directo al Key Benefits of Fine-Tuning in LLMs">​</a></h4>
<ul>
<li><strong>Domain-Specific Accuracy</strong>: Fine-tuning adjusts model weights to better handle data nuances in a given domain.</li>
<li><strong>Resource Efficiency</strong>: Leveraging pre-trained models reduces the computational resources required for training.</li>
<li><strong>Scalability</strong>: Fine-tuning allows models to be customized for multiple tasks without re-training from scratch.</li>
</ul>
<div class="theme-admonition theme-admonition-tip admonition_xJq3 alert alert--success"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 12 16"><path fill-rule="evenodd" d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"></path></svg></span>tip</div><div class="admonitionContent_BuS1"><p>The LLaMA-Factory paper introduces efficient fine-tuning techniques that reduce computational requirements, making large models more accessible for research and industry applications.</p></div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="integrating-neural-networks-with-llms-practical-applications">Integrating Neural Networks with LLMs: Practical Applications<a href="https://edujbarrios.github.io/My-TFG-Logbook/es/blog/neural-networks-fine-tuning-llms#integrating-neural-networks-with-llms-practical-applications" class="hash-link" aria-label="Enlace directo al Integrating Neural Networks with LLMs: Practical Applications" title="Enlace directo al Integrating Neural Networks with LLMs: Practical Applications">​</a></h2>
<p>By fine-tuning neural networks within LLMs, we unlock new possibilities across sectors. For instance, a fine-tuned LLM trained on a dataset of <strong>medical case studies</strong> can assist in diagnostic processes, helping clinicians identify patterns and anomalies. This is particularly relevant in fields where domain-specific expertise is critical, and time is a crucial factor.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="code-example-fine-tuning-a-language-model-with-transformers-and-pytorch">Code Example: Fine-Tuning a Language Model with Transformers and PyTorch<a href="https://edujbarrios.github.io/My-TFG-Logbook/es/blog/neural-networks-fine-tuning-llms#code-example-fine-tuning-a-language-model-with-transformers-and-pytorch" class="hash-link" aria-label="Enlace directo al Code Example: Fine-Tuning a Language Model with Transformers and PyTorch" title="Enlace directo al Code Example: Fine-Tuning a Language Model with Transformers and PyTorch">​</a></h3>
<p>Leveraging the <a href="https://github.com/hiyouga/LLaMA-Factory" target="_blank" rel="noopener noreferrer">LLaMA-Factory repository</a>, we can fine-tune an LLM using efficient training practices as outlined in the research. Here’s an example:</p>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token keyword" style="color:#00009f">from</span><span class="token plain"> transformers </span><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> AutoModelForCausalLM</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> Trainer</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> TrainingArguments</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> torch</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Load a pre-trained LLM model, such as LLaMA or GPT-style models</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">model </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> AutoModelForCausalLM</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">from_pretrained</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string" style="color:#e3116c">"pretrained-llm"</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Define training parameters</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">training_args </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> TrainingArguments</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    output_dir</span><span class="token operator" style="color:#393A34">=</span><span class="token string" style="color:#e3116c">"./results"</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    num_train_epochs</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">3</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    per_device_train_batch_size</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">4</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    warmup_steps</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">500</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    weight_decay</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">0.01</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    logging_dir</span><span class="token operator" style="color:#393A34">=</span><span class="token string" style="color:#e3116c">"./logs"</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Assuming a domain-specific dataset (e.g., medical texts)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">trainer </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> Trainer</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    model</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">model</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    args</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">training_args</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    train_dataset</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">domain_specific_dataset</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">trainer</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">train</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copiar código" title="Copiar" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>In this example, we fine-tune a pre-trained language model using <strong>Transformers</strong> and <strong>PyTorch</strong>. Training arguments, such as <code>num_train_epochs</code> and <code>weight_decay</code>, are critical in managing model performance and computational efficiency, as explored in the LLaMA-Factory paper.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="future-implications-of-fine-tuning-llms">Future Implications of Fine-Tuning LLMs<a href="https://edujbarrios.github.io/My-TFG-Logbook/es/blog/neural-networks-fine-tuning-llms#future-implications-of-fine-tuning-llms" class="hash-link" aria-label="Enlace directo al Future Implications of Fine-Tuning LLMs" title="Enlace directo al Future Implications of Fine-Tuning LLMs">​</a></h2>
<p>The synergy between neural networks and fine-tuning in LLMs could lead to significant advancements in various industries:</p>
<ul>
<li><strong>Healthcare</strong>: LLMs fine-tuned on medical literature and patient data could support diagnostics and personalized treatment recommendations.</li>
<li><strong>Legal and Financial Services</strong>: Fine-tuned models could provide tailored responses and insights, analyzing legal documents or financial statements.</li>
<li><strong>Education</strong>: LLMs could generate custom educational content and adapt to individual learning styles.</li>
</ul>
<p>By building on the research in LLaMA-Factory, developers can create LLMs that are more efficient, accessible, and aligned with domain-specific needs.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="conclusion">Conclusion<a href="https://edujbarrios.github.io/My-TFG-Logbook/es/blog/neural-networks-fine-tuning-llms#conclusion" class="hash-link" aria-label="Enlace directo al Conclusion" title="Enlace directo al Conclusion">​</a></h2>
<p>Neural networks and fine-tuning have brought LLMs to the forefront of AI advancements, as highlighted in the <strong>LLaMA-Factory</strong> paper. By focusing on efficient training techniques, we can harness the full potential of LLMs across sectors, making them more accessible for specialized tasks. Fine-tuning remains a vital part of this development, unlocking the capability of LLMs to perform precise and domain-specific tasks.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="references">References<a href="https://edujbarrios.github.io/My-TFG-Logbook/es/blog/neural-networks-fine-tuning-llms#references" class="hash-link" aria-label="Enlace directo al References" title="Enlace directo al References">​</a></h2>
<ol>
<li>
<p>Hiyouga, L., et al. (2024). <a href="https://arxiv.org/abs/2403.13372" target="_blank" rel="noopener noreferrer">"LLaMA-Factory: Efficient Training Techniques for Large Language Models"</a>. <em>arXiv</em>.</p>
</li>
<li>
<p>GitHub Repository for LLaMA-Factory. (2024). Available at: <a href="https://github.com/hiyouga/LLaMA-Factory" target="_blank" rel="noopener noreferrer">https://github.com/hiyouga/LLaMA-Factory</a></p>
</li>
</ol>]]></content:encoded>
            <category>Neural networks</category>
            <category>fine-tuning</category>
            <category>LLMs</category>
            <category>AI</category>
            <category>deep learning</category>
            <category>transformers</category>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[Enhancing Medical Diagnostics with Prompt Engineering: A Deep Dive into AI Accuracy and Potential]]></title>
            <link>https://edujbarrios.github.io/My-TFG-Logbook/es/blog/prompt-engineering-medical-diagnostics</link>
            <guid>https://edujbarrios.github.io/My-TFG-Logbook/es/blog/prompt-engineering-medical-diagnostics</guid>
            <pubDate>Thu, 07 Nov 2024 14:05:56 GMT</pubDate>
            <description><![CDATA[Medical imaging diagnostics are one of the most promising fields for artificial intelligence applications. With advancements in prompt engineering and fine-tuning models, AI is poised to revolutionize diagnostics, making them faster and, potentially, more accurate. In this article, we’ll explore how prompt engineering and AI tools, including fine-tuning and Python, can impact the field of medical diagnostics.]]></description>
            <content:encoded><![CDATA[<p>Medical imaging diagnostics are one of the most promising fields for artificial intelligence applications. With advancements in <strong>prompt engineering</strong> and <strong>fine-tuning models</strong>, AI is poised to revolutionize diagnostics, making them faster and, potentially, more accurate. In this article, we’ll explore how prompt engineering and AI tools, including fine-tuning and Python, can impact the field of medical diagnostics.</p>
<!-- -->
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="introduction">Introduction<a href="https://edujbarrios.github.io/My-TFG-Logbook/es/blog/prompt-engineering-medical-diagnostics#introduction" class="hash-link" aria-label="Enlace directo al Introduction" title="Enlace directo al Introduction">​</a></h2>
<p>Modern healthcare relies heavily on accurate diagnostic tools, especially in <strong>medical imaging</strong> fields like radiology, MRI, and CT scans. AI-driven tools can assist medical professionals by identifying patterns and potential issues that might otherwise go unnoticed. But the real breakthrough lies in <strong>prompt engineering</strong>, where tailored prompts can guide AI models to make more precise predictions.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="what-is-prompt-engineering">What is Prompt Engineering?<a href="https://edujbarrios.github.io/My-TFG-Logbook/es/blog/prompt-engineering-medical-diagnostics#what-is-prompt-engineering" class="hash-link" aria-label="Enlace directo al What is Prompt Engineering?" title="Enlace directo al What is Prompt Engineering?">​</a></h2>
<p>Prompt engineering is the art and science of designing inputs for AI models to maximize their effectiveness. In the context of medical diagnostics, a well-crafted prompt can help an AI model focus on specific features in an image, such as abnormalities or signs of disease. For example, a prompt could instruct the model to "identify and categorize any growths that resemble tumors in this CT scan," thereby streamlining the diagnostic process.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="key-benefits-of-prompt-engineering-in-medical-imaging">Key Benefits of Prompt Engineering in Medical Imaging<a href="https://edujbarrios.github.io/My-TFG-Logbook/es/blog/prompt-engineering-medical-diagnostics#key-benefits-of-prompt-engineering-in-medical-imaging" class="hash-link" aria-label="Enlace directo al Key Benefits of Prompt Engineering in Medical Imaging" title="Enlace directo al Key Benefits of Prompt Engineering in Medical Imaging">​</a></h3>
<ul>
<li><strong>Increased Accuracy</strong>: A targeted prompt can help narrow down the AI's focus, leading to higher diagnostic accuracy.</li>
<li><strong>Consistency in Diagnostics</strong>: Human error is reduced as AI provides a consistent second opinion.</li>
<li><strong>Speed</strong>: Prompt engineering allows for quicker diagnostics, enabling faster patient response times.</li>
</ul>
<div class="theme-admonition theme-admonition-tip admonition_xJq3 alert alert--success"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 12 16"><path fill-rule="evenodd" d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"></path></svg></span>tip</div><div class="admonitionContent_BuS1"><p>AI-driven tools in medical imaging could serve as an additional diagnostic layer, providing insights that might take years of experience for a human specialist to acquire.</p></div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="the-role-of-fine-tuning-for-improved-diagnostics">The Role of Fine-Tuning for Improved Diagnostics<a href="https://edujbarrios.github.io/My-TFG-Logbook/es/blog/prompt-engineering-medical-diagnostics#the-role-of-fine-tuning-for-improved-diagnostics" class="hash-link" aria-label="Enlace directo al The Role of Fine-Tuning for Improved Diagnostics" title="Enlace directo al The Role of Fine-Tuning for Improved Diagnostics">​</a></h2>
<p>While prompt engineering is essential, <strong>fine-tuning</strong> plays an equally critical role. Fine-tuning involves training a pre-existing AI model on a specific dataset to improve its performance in a particular domain—like medical imaging. With tools such as <strong>PyTorch</strong> and <strong>TensorFlow</strong>, fine-tuning models for specific medical tasks has become more accessible.</p>
<p>For instance, a model can be fine-tuned on a dataset of MRI scans to recognize early signs of <strong>Alzheimer's disease</strong>. By continuously refining the model with relevant data, it becomes more adept at spotting nuanced patterns that might indicate disease progression.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="fine-tuning-in-practice">Fine-Tuning in Practice<a href="https://edujbarrios.github.io/My-TFG-Logbook/es/blog/prompt-engineering-medical-diagnostics#fine-tuning-in-practice" class="hash-link" aria-label="Enlace directo al Fine-Tuning in Practice" title="Enlace directo al Fine-Tuning in Practice">​</a></h3>
<div class="language-python codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-python codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token keyword" style="color:#00009f">from</span><span class="token plain"> transformers </span><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> AutoModelForImageClassification</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> Trainer</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> TrainingArguments</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">import</span><span class="token plain"> torch</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Load a pre-trained model and fine-tune it</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">model </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> AutoModelForImageClassification</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">from_pretrained</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string" style="color:#e3116c">"pretrained-model"</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Training parameters</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">training_args </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> TrainingArguments</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    output_dir</span><span class="token operator" style="color:#393A34">=</span><span class="token string" style="color:#e3116c">"./results"</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    num_train_epochs</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">3</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    per_device_train_batch_size</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">8</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Fine-tune on a medical imaging dataset</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">trainer </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> Trainer</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    model</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">model</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    args</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">training_args</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    train_dataset</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">medical_imaging_dataset</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">trainer</span><span class="token punctuation" style="color:#393A34">.</span><span class="token plain">train</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copiar código" title="Copiar" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>]]></content:encoded>
            <category>Prompt-engineering</category>
            <category>medicine</category>
            <category>AI</category>
            <category>medical imaging</category>
            <category>fine-tuning</category>
            <category>Python</category>
        </item>
    </channel>
</rss>